{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify looped team-season url\n",
    "team = 'MIL'\n",
    "year = 2022\n",
    "windows = [1, 2, 5, 10, 25]\n",
    "team_dic = {'Milwaukee Bucks' : 'MIL', 'Chicago Bulls': 'CHI', 'Golden State Warriors': 'GSW'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.basketball-reference.com/teams/{team}/{year}_games.html'\n",
    "soup = BeautifulSoup(requests.get(url).content, 'lxml') # Create soup instance of this page\n",
    "while soup.find('tr', class_='thead') is not None: # Decompose all headers\n",
    "    soup.find('tr', class_='thead').decompose()\n",
    "\n",
    "# Create DataFrame from the team's schedule\n",
    "df = pd.read_html(str(soup.find('table')))[0]\n",
    "# Search for the columns which contain the W/L and the venue\n",
    "for col in df.columns:\n",
    "    if '@' in set(df[col]) :\n",
    "        venue_col = col\n",
    "    if ('W' in set(df[col]) or 'L' in set(df[col])) and (col != 'Streak'):\n",
    "        win_col = col\n",
    "df = df[df['Notes'] != 'Play-In Game'] # Get rid of play-in games\n",
    "df = df.drop(columns = ['W', 'L']) # Tidy-up the data\n",
    "df = df.rename(columns = {'Tm': 'PTS', 'Opp': 'PTS_opp', win_col : 'W', venue_col: 'Venue'}) # Rename columns\n",
    "df['Team'] = len(df) * [team] # Keep track of team\n",
    "df['W'] = df['W'].replace('W', 1).replace('L', 0) # Replace Ws & Ls by 1s & 0s\n",
    "df['Date'] = pd.to_datetime(df['Date']) # Ensure dates are in datetime format\n",
    "df['Opponent'] = df['Opponent'].apply(lambda x: team_dic.get(x)) # Get opponent team code\n",
    "df['Venue'] = df['Venue'].replace(np.nan, 1).replace('@', 0) # Keep track of who played at home\n",
    "df['Streak'] = df['Streak'].apply(lambda x: {'W':1,'L':-1}.get(x.split()[0]) * float(x.split()[1])) # Transform the streak into numeric format\n",
    "df['Streak'] = [np.nan] + list(df['Streak'])[:-1] # Shift streak by one row -- for forecasting\n",
    "df = df[['Date', 'G', 'Venue', 'Team', 'Opponent', 'W', 'PTS', 'PTS_opp', 'Streak']] # Only keep necessary columns \n",
    "\n",
    "# Loop through features\n",
    "for stat, underlying_stat in zip(['W/L%', 'ORtg', 'DRtg'], ['W', 'PTS', 'PTS_opp']):\n",
    "    # Calculate rolling means of features at each given window\n",
    "    df[stat] = [np.nan] + list(df[underlying_stat].rolling(1000, min_periods = 1).mean())[:-1]\n",
    "    for w in windows:\n",
    "        df[stat + '_' + str(w)] = [np.nan] + list(df[underlying_stat].rolling(w, min_periods = 1).mean())[:-1]\n",
    "# Calculate NRtg features\n",
    "df['NRtg'] = df['ORtg'] - df['DRtg']\n",
    "for w in windows :\n",
    "    df[f'NRtg_{w}'] = df[f'ORtg_{w}'] - df[f'DRtg_{w}']\n",
    "df['Rest'] = df['Date'].diff().apply(lambda x: x.total_seconds() / (24 * 3600))\n",
    "# Calculate the number of games played in the last week prior to the game\n",
    "df['Games_past_week'] = df['Date'].apply(lambda x: len(df[(df['Date'] < x) & (df['Date'] > x - timedelta(days = 7.5))])).astype(float)\n",
    "# Calculate the H2H record previous to each game\n",
    "dfs_h2h = [] # Loop for each potential opponent\n",
    "for opp in team_dic.values() :\n",
    "    if opp != team :\n",
    "        df_h2h = df.copy().groupby('Opponent').get_group(opp) # Get games against looped opponent\n",
    "        df_h2h['H2H'] = [np.nan] + list(df_h2h['W'].rolling(1000, min_periods = 1).mean())[:-1] # Calculate the rolling H2H record\n",
    "        dfs_h2h.append(df_h2h) # append \"mini\"-DataFrame with rolling H2H record for each opponent\n",
    "# Re-assemble the data by concatenating the \"mini\"-DataFrames\n",
    "df = pd.concat(dfs_h2h).sort_values('Date').reset_index(drop = True)\n",
    "\n",
    "# Build DataFrame of team's home games\n",
    "df_home = df.copy().groupby('Venue').get_group(1)\n",
    "df_home = df_home.drop(columns = ['Venue'])\n",
    "for col in df_home.columns: # Add a home suffix to all columns\n",
    "        df_home = df_home.rename(columns = {col: col + '_home'})\n",
    "# But, revert change for merge columns and rename some IDs columns\n",
    "df_home = df_home.rename(columns = {'Date_home': 'Date', 'Opponent_home': 'Away', 'PTS_opp_home': 'PTS_away', 'Team_home': 'Home'})\n",
    "df_home['HomeW/L%_home'] = [np.nan] + list(df_home['W_home'].rolling(1000, min_periods = 1).mean())[:-1]\n",
    "df_home['ID'] = df_home['Date'].apply(lambda x: str(x)[2:10].replace('-', '')) + df_home['Home'] + df_home['Away'] # Re-create the unique ID for each game\n",
    "\n",
    "# Build DataFrame of team's away games\n",
    "df_away = df.copy().groupby('Venue').get_group(0)\n",
    "df_away = df_away.drop(columns = ['Venue'])\n",
    "for col in df_away.columns: # Add an away suffix to all columns\n",
    "    df_away = df_away.rename(columns = {col: col + '_away'})\n",
    "# But, revert change for merge columns and rename some IDs columns\n",
    "df_away = df_away.rename(columns = {'Date_away': 'Date', 'Opponent_away': 'Home', 'PTS_opp_away': 'PTS_home', 'Team_away': 'Away'})\n",
    "df_away['AwayW/L%_away'] = [np.nan] + list(df_away['W_away'].rolling(1000, min_periods = 1).mean())[:-1]\n",
    "df_away['ID'] = df_away['Date'].apply(lambda x: str(x)[2:10].replace('-', '')) + df_away['Home'] + df_away['Away'] # Re-create the unique ID for each game\n",
    "# Append the team home & away DataFrame to the lists\n",
    "data_team_home.append(df_home)\n",
    "data_team_away.append(df_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.basketball-reference.com/leagues/NBA_{year}.html'\n",
    "# Create a soup object from the url\n",
    "soup = BeautifulSoup(requests.get(url).content, 'lxml')\n",
    "table = soup.find('table', id = 'per_game-team')\n",
    "df = pd.read_html(str(table))[0] # Get data of all the team which competed in the looped season\n",
    "df['Team'] = df['Team'].str.replace('*', '', regex = False) # Clean-up team names\n",
    "df = df[df['Rk'].notna()] # Get rid of average row\n",
    "# Create a list of the team codes from the hidden urls\n",
    "team_codes = pd.Series(table.find_all('a', href = True)).apply(lambda x: x['href'].split('/')[2])\n",
    "team_dic = dict(zip(df['Team'], team_codes)) # Map each team to its team code name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   2. SCRAPE SCHEDULE OF EACH TEAM\n",
    "\n",
    "data_team_home = [] # Initiate lists for all home and away games\n",
    "data_team_away = []\n",
    "n_teams = len(team_dic)\n",
    "for step, team in enumerate(list(team_dic.values())[:4]) : # Loop for every team of the season\n",
    "\n",
    "    # Specify looped team-season url\n",
    "    url = f'https://www.basketball-reference.com/teams/{team}/{year}_games.html'\n",
    "    soup = BeautifulSoup(requests.get(url).content, 'lxml') # Create soup instance of this page\n",
    "    while soup.find('tr', class_ = 'thead') is not None: # Decompose all headers\n",
    "        soup.find('tr', class_ = 'thead').decompose()\n",
    "\n",
    "    # Create DataFrame from the team's schedule\n",
    "    df = pd.read_html(str(soup.find('table')))[0]\n",
    "    # Search for the columns which contain the W/L and the venue\n",
    "    for col in df.columns:\n",
    "        if '@' in set(df[col]) :\n",
    "            venue_col = col\n",
    "        if ('W' in set(df[col]) or 'L' in set(df[col])) and (col != 'Streak'):\n",
    "            win_col = col\n",
    "    df = df[df['Notes'] != 'Play-In Game'] # Get rid of play-in games\n",
    "    df = df.drop(columns = ['W', 'L']) # Tidy-up the data\n",
    "    df = df.rename(columns = {'Tm': 'PTS', 'Opp': 'PTS_opp', win_col : 'W', venue_col: 'Venue'}) # Rename columns\n",
    "    df['Team'] = len(df) * [team] # Keep track of team\n",
    "    df['W'] = df['W'].replace('W', 1).replace('L', 0) # Replace Ws & Ls by 1s & 0s\n",
    "    df['Date'] = pd.to_datetime(df['Date']) # Ensure dates are in datetime format\n",
    "    df['Opponent'] = df['Opponent'].apply(lambda x: team_dic.get(x)) # Get opponent team code\n",
    "    df['Venue'] = df['Venue'].replace(np.nan, 1).replace('@', 0) # Keep track of who played at home\n",
    "    df['Streak'] = df['Streak'].apply(lambda x: {'W':1,'L':-1}.get(x.split()[0]) * float(x.split()[1])) # Transform the streak into numeric format\n",
    "    df['Streak'] = [np.nan] + list(df['Streak'])[:-1] # Shift streak by one row -- for forecasting\n",
    "    df = df[['Date', 'G', 'Venue', 'Team', 'Opponent', 'W', 'PTS', 'PTS_opp', 'Streak']] # Only keep necessary columns \n",
    "\n",
    "    # Loop through features\n",
    "    for stat, underlying_stat in zip(['W/L%', 'ORtg', 'DRtg'], ['W', 'PTS', 'PTS_opp']):\n",
    "        # Calculate rolling means of features at each given window\n",
    "        df[stat] = [np.nan] + list(df[underlying_stat].rolling(1000, min_periods = 1).mean())[:-1]\n",
    "        for w in windows:\n",
    "            df[stat + '_' + str(w)] = [np.nan] + list(df[underlying_stat].rolling(w, min_periods = 1).mean())[:-1]\n",
    "    # Calculate NRtg features\n",
    "    df['NRtg'] = df['ORtg'] - df['DRtg']\n",
    "    for w in windows :\n",
    "        df[f'NRtg_{w}'] = df[f'ORtg_{w}'] - df[f'DRtg_{w}']\n",
    "    df['Rest'] = df['Date'].diff().apply(lambda x: x.total_seconds() / (24 * 3600))\n",
    "    # Calculate the number of games played in the last week prior to the game\n",
    "    df['Games_past_week'] = df['Date'].apply(lambda x: len(df[(df['Date'] < x) & (df['Date'] > x - timedelta(days = 7.5))])).astype(float)\n",
    "    # Calculate the H2H record previous to each game\n",
    "    dfs_h2h = [] # Loop for each potential opponent\n",
    "    for opp in team_dic.values() :\n",
    "        if opp != team :\n",
    "            df_h2h = df.copy().groupby('Opponent').get_group(opp) # Get games against looped opponent\n",
    "            df_h2h['H2H'] = [np.nan] + list(df_h2h['W'].rolling(1000, min_periods = 1).mean())[:-1] # Calculate the rolling H2H record\n",
    "            dfs_h2h.append(df_h2h) # append \"mini\"-DataFrame with rolling H2H record for each opponent\n",
    "    # Re-assemble the data by concatenating the \"mini\"-DataFrames\n",
    "    df = pd.concat(dfs_h2h).sort_values('Date').reset_index(drop = True)\n",
    "\n",
    "    # Build DataFrame of team's home games\n",
    "    df_home = df.copy().groupby('Venue').get_group(1)\n",
    "    df_home = df_home.drop(columns = ['Venue'])\n",
    "    for col in df_home.columns: # Add a home suffix to all columns\n",
    "            df_home = df_home.rename(columns = {col: col + '_home'})\n",
    "    # But, revert change for merge columns and rename some IDs columns\n",
    "    df_home = df_home.rename(columns = {'Date_home': 'Date', 'Opponent_home': 'Away', 'PTS_opp_home': 'PTS_away', 'Team_home': 'Home'})\n",
    "    df_home['HomeW/L%_home'] = [np.nan] + list(df_home['W_home'].rolling(1000, min_periods = 1).mean())[:-1]\n",
    "    df_home['ID'] = df_home['Date'].apply(lambda x: str(x)[2:10].replace('-', '')) + df_home['Home'] + df_home['Away'] # Re-create the unique ID for each game\n",
    "\n",
    "    # Build DataFrame of team's away games\n",
    "    df_away = df.copy().groupby('Venue').get_group(0)\n",
    "    df_away = df_away.drop(columns = ['Venue'])\n",
    "    for col in df_away.columns: # Add an away suffix to all columns\n",
    "        df_away = df_away.rename(columns = {col: col + '_away'})\n",
    "    # But, revert change for merge columns and rename some IDs columns\n",
    "    df_away = df_away.rename(columns = {'Date_away': 'Date', 'Opponent_away': 'Home', 'PTS_opp_away': 'PTS_home', 'Team_away': 'Away'})\n",
    "    df_away['AwayW/L%_away'] = [np.nan] + list(df_away['W_away'].rolling(1000, min_periods = 1).mean())[:-1]\n",
    "    df_away['ID'] = df_away['Date'].apply(lambda x: str(x)[2:10].replace('-', '')) + df_away['Home'] + df_away['Away'] # Re-create the unique ID for each game\n",
    "    # Append the team home & away DataFrame to the lists\n",
    "    data_team_home.append(df_home)\n",
    "    data_team_away.append(df_away)\n",
    "\n",
    "   # sleep(10) # Let's avoid getting rate limited by BBRef ...\n",
    "\n",
    "\n",
    "\n",
    "#   3. BRING DATA ALL TEAMS TOGETHER ###\n",
    "\n",
    "# Get all home stats and away stats in single DataFrame\n",
    "homes = pd.concat(data_team_home)\n",
    "aways = pd.concat(data_team_away)\n",
    "    \n",
    "# Merge away and home games on the unique game ID (and overlapping columns)\n",
    "data = homes.merge(aways, on = ['ID', 'Date', 'Home', 'Away', 'PTS_home', 'PTS_away'])\n",
    "data['PTS_diff'] = data['PTS_home'] - data['PTS_away'] # Calculate the points difference for each game\n",
    "data = data.sort_values('Date').reset_index(drop = True) # Make sure data is in temporal order\n",
    "# Make a list of features\n",
    "features = [x for x in list(data) if 'W/L%' in x or 'ORtg' in x or 'DRtg' in x or 'Streak' in x or 'NRtg' in x or 'Rest' in x]\n",
    "# Re-order columns in a more readable order\n",
    "#  data = data[['ID', 'Date', 'G_home', 'G_away', 'Home', 'Away', 'W_home', 'PTS_home', 'PTS_away', 'PTS_diff'] + self.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('nbaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8158d229fe7301e640acb43d488c0efce3cd8ada31ff414dc1808c070c07cefa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
